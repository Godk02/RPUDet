digraph {
	graph [size="16.2,16.2"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	22519818393920 [label="
 (1, 512, 64, 64)" fillcolor=darkolivegreen1]
	22519818408768 [label=CatBackward]
	22519818408864 -> 22519818408768
	22519818408864 [label=ThnnConv2DBackward]
	22519818408576 -> 22519818408864
	22519818392384 [label="conv_layers.2.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	22519818392384 -> 22519818408576
	22519818408576 [label=AccumulateGrad]
	22519818408672 -> 22519818408864
	22519818392512 [label="conv_layers.2.bias
 (256)" fillcolor=lightblue]
	22519818392512 -> 22519818408672
	22519818408672 [label=AccumulateGrad]
	22519818408816 -> 22519818408768
	22519818408816 [label=ThnnConv2DBackward]
	22519818408960 -> 22519818408816
	22519818408960 [label=MulBackward0]
	22519818409056 -> 22519818408960
	22519818409056 [label=MulBackward0]
	22519818409200 -> 22519818409056
	22519818409200 [label=UnsqueezeBackward0]
	22519818409296 -> 22519818409200
	22519818409296 [label=UnsqueezeBackward0]
	22519818409392 -> 22519818409296
	22519818409392 [label=SigmoidBackward]
	22519818409488 -> 22519818409392
	22519818409488 [label=AddmmBackward]
	22519818409584 -> 22519818409488
	22519818266944 [label="linear_layers.2.bias
 (512)" fillcolor=lightblue]
	22519818266944 -> 22519818409584
	22519818409584 [label=AccumulateGrad]
	22519818409536 -> 22519818409488
	22519818409536 [label=AddmmBackward]
	22519818409680 -> 22519818409536
	22519818266432 [label="linear.bias
 (1024)" fillcolor=lightblue]
	22519818266432 -> 22519818409680
	22519818409680 [label=AccumulateGrad]
	22519818409728 -> 22519818409536
	22519818409728 [label=MmBackward]
	22519818409872 -> 22519818409728
	22519818409872 [label=TransposeBackward0]
	22519818410064 -> 22519818409872
	22519818410064 [label=MmBackward]
	22519818410160 -> 22519818410064
	22519818410160 [label=MmBackward]
	22519818410256 -> 22519818410160
	22519818410256 [label=LeakyReluBackward0]
	22519818410400 -> 22519818410256
	22519818410400 [label=MmBackward]
	22519818410496 -> 22519818410400
	22519818410496 [label=MmBackward]
	22519818410592 -> 22519818410496
	22519822797120 [label="gc1.weight
 (512, 1024)" fillcolor=lightblue]
	22519822797120 -> 22519818410592
	22519818410592 [label=AccumulateGrad]
	22519818410208 -> 22519818410160
	22519818266304 [label="gc2.weight
 (1024, 512)" fillcolor=lightblue]
	22519818266304 -> 22519818410208
	22519818410208 [label=AccumulateGrad]
	22519818409776 -> 22519818409536
	22519818409776 [label=TBackward]
	22519818410112 -> 22519818409776
	22519833376000 [label="linear.weight
 (1024, 10)" fillcolor=lightblue]
	22519833376000 -> 22519818410112
	22519818410112 [label=AccumulateGrad]
	22519818409104 -> 22519818409488
	22519818409104 [label=TBackward]
	22519818410544 -> 22519818409104
	22519818266816 [label="linear_layers.2.weight
 (512, 1024)" fillcolor=lightblue]
	22519818266816 -> 22519818410544
	22519818410544 [label=AccumulateGrad]
	22519818409008 -> 22519818408960
	22519818409008 [label=ViewBackward]
	22519818409344 -> 22519818409008
	22519818409344 [label=SigmoidBackward]
	22519818409632 -> 22519818409344
	22519818409632 [label=AddmmBackward]
	22519818409920 -> 22519818409632
	22519818343680 [label="attention_layers.2.fc.2.bias
 (512)" fillcolor=lightblue]
	22519818343680 -> 22519818409920
	22519818409920 [label=AccumulateGrad]
	22519818410016 -> 22519818409632
	22519818410016 [label=ReluBackward0]
	22519818409824 -> 22519818410016
	22519818409824 [label=AddmmBackward]
	22519818410640 -> 22519818409824
	22519818343360 [label="attention_layers.2.fc.0.bias
 (256)" fillcolor=lightblue]
	22519818343360 -> 22519818410640
	22519818410640 [label=AccumulateGrad]
	22519818410688 -> 22519818409824
	22519818410688 [label=ViewBackward]
	22519818410736 -> 22519818410688
	22519818410736 [label=MeanBackward1]
	22519818409056 -> 22519818410736
	22519818410352 -> 22519818409824
	22519818410352 [label=TBackward]
	22519818410880 -> 22519818410352
	22519818343232 [label="attention_layers.2.fc.0.weight
 (256, 512)" fillcolor=lightblue]
	22519818343232 -> 22519818410880
	22519818410880 [label=AccumulateGrad]
	22519818409152 -> 22519818409632
	22519818409152 [label=TBackward]
	22519818410928 -> 22519818409152
	22519818343552 [label="attention_layers.2.fc.2.weight
 (512, 256)" fillcolor=lightblue]
	22519818343552 -> 22519818410928
	22519818410928 [label=AccumulateGrad]
	22519818408576 -> 22519818408816
	22519818408672 -> 22519818408816
	22519818408768 -> 22519818393920
}
